{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = \"f04\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_identity = pd.read_csv(\"../data/raw/train_identity.csv\")\n",
    "train_transaction = pd.read_csv(\"../data/raw/train_transaction.csv\")\n",
    "test_identity = pd.read_csv(\"../data/raw/test_identity.csv\")\n",
    "test_transaction = pd.read_csv(\"../data/raw/test_transaction.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transaction[\"istrain\"] = 1\n",
    "test_transaction[\"istrain\"] = 0\n",
    "test_transaction[\"isFraud\"] = np.nan\n",
    "\n",
    "concat_transaction = pd.concat([train_transaction, test_transaction], axis=0, sort=False)\n",
    "concat_identity = pd.concat([train_identity, test_identity], axis=0, sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# とりあえず、マージ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.merge(concat_transaction,concat_identity, on ='TransactionID', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 効いていそうな特徴を追加(カーネル参考)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['TransactionAmt_to_mean_card1'] = all_data['TransactionAmt'] / all_data.groupby(['card1'])['TransactionAmt'].transform('mean')\n",
    "all_data['TransactionAmt_to_mean_card4'] = all_data['TransactionAmt'] / all_data.groupby(['card4'])['TransactionAmt'].transform('mean')\n",
    "all_data['TransactionAmt_to_std_card1'] = all_data['TransactionAmt'] / all_data.groupby(['card1'])['TransactionAmt'].transform('std')\n",
    "all_data['TransactionAmt_to_std_card4'] = all_data['TransactionAmt'] / all_data.groupby(['card4'])['TransactionAmt'].transform('std')\n",
    "\n",
    "\n",
    "all_data['id_02_to_mean_card1'] = all_data['id_02'] / all_data.groupby(['card1'])['id_02'].transform('mean')\n",
    "all_data['id_02_to_mean_card4'] = all_data['id_02'] / all_data.groupby(['card4'])['id_02'].transform('mean')\n",
    "all_data['id_02_to_std_card1'] = all_data['id_02'] / all_data.groupby(['card1'])['id_02'].transform('std')\n",
    "all_data['id_02_to_std_card4'] = all_data['id_02'] / all_data.groupby(['card4'])['id_02'].transform('std')\n",
    "\n",
    "\n",
    "all_data['D15_to_mean_card1'] = all_data['D15'] / all_data.groupby(['card1'])['D15'].transform('mean')\n",
    "all_data['D15_to_mean_card4'] = all_data['D15'] / all_data.groupby(['card4'])['D15'].transform('mean')\n",
    "all_data['D15_to_std_card1'] = all_data['D15'] / all_data.groupby(['card1'])['D15'].transform('std')\n",
    "all_data['D15_to_std_card4'] = all_data['D15'] / all_data.groupby(['card4'])['D15'].transform('std')\n",
    "\n",
    "\n",
    "all_data['D15_to_mean_addr1'] = all_data['D15'] / all_data.groupby(['addr1'])['D15'].transform('mean')\n",
    "all_data['D15_to_mean_addr2'] = all_data['D15'] / all_data.groupby(['addr2'])['D15'].transform('mean')\n",
    "all_data['D15_to_std_addr1'] = all_data['D15'] / all_data.groupby(['addr1'])['D15'].transform('std')\n",
    "all_data['D15_to_std_addr2'] = all_data['D15'] / all_data.groupby(['addr2'])['D15'].transform('std')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# card1を個人のIDと仮定して、前回の情報を抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "card1_list = all_data['card1'].drop_duplicates().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17091/17091 [05:17<00:00, 53.89it/s]\n"
     ]
    }
   ],
   "source": [
    "# card1がひとつ前に行った時間と金額を特徴に入れる\n",
    "card_tra = pd.DataFrame()\n",
    "\n",
    "for card_num in tqdm(card1_list):\n",
    "    card_temp = all_data.query('card1 == @card_num')\n",
    "    card_temp_shift = card_temp[['TransactionDT','TransactionAmt']].shift(1)\n",
    "    card_temp_shift = card_temp_shift.rename(columns={'TransactionDT':'TransactionDT_shift','TransactionAmt':'TransactionAmt_shift'})\n",
    "    card_tra = pd.concat([card_tra, card_temp_shift],axis = 0)\n",
    "\n",
    "all_data = pd.concat([all_data,card_tra],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['TransactionDT_diff'] = all_data['TransactionDT'] -  all_data['TransactionDT_shift']\n",
    "all_data['TransactionAmt_diff'] = all_data['TransactionAmt'] -  all_data['TransactionAmt_shift']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = all_data.drop(['TransactionDT_shift','TransactionAmt_shift'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TransactionAmtの非整数部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[\"TransactionAmtmod\"] = all_data[\"TransactionAmt\"] - all_data[\"TransactionAmt\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ['TransactionAmt','TransactionAmtmod']:\n",
    "    all_data[column] = all_data[column].astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TransactionDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "all_data['TransactionDT'] = pd.to_datetime('2017-12-01') + pd.to_timedelta(all_data['TransactionDT'],unit='s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 時間特徴追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat_transaction[\"day\"] = concat_transaction[\"TransactionDT\"].dt.day\n",
    "all_data[\"hour\"] = all_data[\"TransactionDT\"].dt.hour\n",
    "# concat_transaction[\"minute\"] = concat_transaction[\"TransactionDT\"].dt.minute\n",
    "#concat_transaction[\"second\"] = concat_transaction[\"TransactionDT\"].dt.second\n",
    "all_data[\"dayofweek\"] = all_data[\"TransactionDT\"].dt.dayofweek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# email特徴追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[[\"P_emaildomain_1\",\"P_emaildomain_2\",\"P_emaildomain_3\"]] = all_data['P_emaildomain'].str.split('.',expand=True)\n",
    "all_data[[\"R_emaildomain_1\",\"R_emaildomain_2\",\"R_emaildomain_3\"]] = all_data['R_emaildomain'].str.split('.',expand=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### カテゴリとして扱う特徴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['id_12',\n",
    "            'id_13', \n",
    "            'id_14', \n",
    "            'id_15', \n",
    "            'id_16',\n",
    "            'id_17', \n",
    "            'id_18',\n",
    "            'id_19',\n",
    "            'id_20', \n",
    "            'id_21',\n",
    "            'id_22',\n",
    "            'id_23',\n",
    "            'id_24',\n",
    "            'id_25', \n",
    "            'id_26',\n",
    "            'id_27', \n",
    "            'id_28', \n",
    "            'id_29',\n",
    "            'id_30',\n",
    "            'id_31',\n",
    "            'id_32', \n",
    "            'id_33',\n",
    "            'id_34',\n",
    "            'id_35', \n",
    "            'id_36', \n",
    "            'id_37', \n",
    "            'id_38',\n",
    "            'DeviceType', \n",
    "            'DeviceInfo',\n",
    "            'ProductCD',\n",
    "            'card4',\n",
    "            'card6',\n",
    "            'M4',\n",
    "            'P_emaildomain',\n",
    "            'R_emaildomain',\n",
    "            'card1', \n",
    "            'card2', \n",
    "            'card3', \n",
    "            'card5',\n",
    "            'addr1',\n",
    "            'addr2',\n",
    "            'M1',\n",
    "            'M2', \n",
    "            'M3',\n",
    "            'M5',\n",
    "            'M6',\n",
    "            'M7',\n",
    "            'M8',\n",
    "            'M9',\n",
    "            'P_emaildomain_1', \n",
    "            'P_emaildomain_2',\n",
    "            'P_emaildomain_3', \n",
    "            'R_emaildomain_1',\n",
    "            'R_emaildomain_2', \n",
    "            'R_emaildomain_3',\n",
    "            'ProductCD']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# カウントエンコーディング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_encoder(df, column):\n",
    "    df[column] = df[column].fillna(-1)\n",
    "    count_enc = df.groupby(column)[column].count()\n",
    "    df[f'count_enc_{column}'] = df[column].map(count_enc)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cat_cols:\n",
    "    all_data = count_encoder(all_data, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for column in cat_cols:\n",
    "#     all_data[column] = all_data[column].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 結合していたtrainとtestを分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_processed = all_data.query('istrain == 1')\n",
    "test_processed = all_data.query('istrain == 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_processed = test_processed.drop([\"isFraud\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import feather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 書き込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feather.write_dataframe(train_processed, f'../data/processed/train_processed_{version}.feather')\n",
    "# feather.write_dataframe(test_processed, f'../data/processed/test_processed_{version}.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_processed.to_csv('../data/processed/train_processed_f04.csv',index=False,header=True)\n",
    "test_processed.to_csv('../data/processed/test_processed_f04.csv',index=False,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
